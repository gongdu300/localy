# Travel OS ë°ì´í„° ì•„í‚¤í…ì²˜ & RAG ì „ëµ
## í•˜ì´ë¸Œë¦¬ë“œ ë©€í‹°ëª¨ë‹¬ ë°ì´í„° ì‹œìŠ¤í…œ

> ë‹¨ìˆœ RDS + Vector DBë¥¼ ë„˜ì–´ì„  **ì§€ëŠ¥í˜• ë°ì´í„° ë ˆì´ì–´** ì„¤ê³„

---

## ğŸ“š ëª©ì°¨

1. [í˜„ì¬ ê³„íš vs ê°œì„ ì•ˆ](#1-í˜„ì¬-ê³„íš-vs-ê°œì„ ì•ˆ)
2. [í•˜ì´ë¸Œë¦¬ë“œ ì €ì¥ ì „ëµ](#2-í•˜ì´ë¸Œë¦¬ë“œ-ì €ì¥-ì „ëµ)
3. [ë©€í‹°ëª¨ë‹¬ RAG ì‹œìŠ¤í…œ](#3-ë©€í‹°ëª¨ë‹¬-rag-ì‹œìŠ¤í…œ)
4. [ì‹¤ì‹œê°„ ë°ì´í„° íŒŒì´í”„ë¼ì¸](#4-ì‹¤ì‹œê°„-ë°ì´í„°-íŒŒì´í”„ë¼ì¸)
5. [ìºì‹± & ì„±ëŠ¥ ìµœì í™”](#5-ìºì‹±--ì„±ëŠ¥-ìµœì í™”)
6. [ê°œì¸ì •ë³´ & ë³´ì•ˆ](#6-ê°œì¸ì •ë³´--ë³´ì•ˆ)

---

## 1. í˜„ì¬ ê³„íš vs ê°œì„ ì•ˆ

### 1.1 í˜„ì¬ ê³„íš (Good)

```
PostgreSQL (RDS)          Vector DB (Pinecone)
â”œâ”€ êµ¬ì¡°í™” ë°ì´í„°           â”œâ”€ ëŒ€í™” ë¡œê·¸ ì„ë² ë”©
â”œâ”€ ì—¬í–‰ ê¸°ë¡              â”œâ”€ ì‚¬ìš©ì ì„ í˜¸ë„ ë²¡í„°
â””â”€ ë§›ì§‘/ìˆ™ì†Œ ì •ë³´         â””â”€ ë¦¬ë·° ì„ë² ë”©
```

**ë¬¸ì œì :**
1. âŒ ì •í˜•/ë¹„ì •í˜• ë°ì´í„° ë¶„ë¦¬ â†’ ê²€ìƒ‰ ë¹„íš¨ìœ¨
2. âŒ ê´€ê³„ ë°ì´í„° í‘œí˜„ í•œê³„ (ì¹œêµ¬ ê´€ê³„, POI ì—°ê²° ë“±)
3. âŒ ì‹¤ì‹œê°„ ë°ì´í„° ì²˜ë¦¬ ë¶€ì¡±
4. âŒ ëŒ€í™” ë¡œê·¸ë§Œ ë²¡í„°í™” â†’ ë‹¤ë¥¸ ë°ì´í„°ë„ ê²€ìƒ‰ ê°€ëŠ¥í•´ì•¼ í•¨

### 1.2 ê°œì„ ì•ˆ (Better)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Application Layer                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“â†‘
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Unified Query Layer                        â”‚
â”‚          "Single Entry Point for All Data Access"           â”‚
â”‚                                                             â”‚
â”‚  - Query Router (ì–´ë””ì„œ ê²€ìƒ‰í• ì§€ ìë™ ê²°ì •)                    â”‚
â”‚  - Hybrid Search (BM25 + Vector + Graph)                   â”‚
â”‚  - Result Fusion (ì—¬ëŸ¬ ì†ŒìŠ¤ ê²°ê³¼ í†µí•©)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“â†‘
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Storage Layer                            â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Vector DBâ”‚  â”‚  Graph DB â”‚  â”‚    RDS   â”‚  â”‚  Cache   â”‚   â”‚
â”‚  â”‚ (Pinecone)â”‚  â”‚  (Neo4j)  â”‚  â”‚(Postgres)â”‚  â”‚ (Redis)  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚Time-Seriesâ”‚  â”‚ Object   â”‚  â”‚ Search   â”‚                 â”‚
â”‚  â”‚(InfluxDB) â”‚  â”‚Store(S3) â”‚  â”‚(Elastic) â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. í•˜ì´ë¸Œë¦¬ë“œ ì €ì¥ ì „ëµ

### 2.1 ë°ì´í„° ë¶„ë¥˜ & ì €ì¥ì†Œ ì„ íƒ

#### ì›ì¹™: **"Right Data, Right Place"**

| ë°ì´í„° ìœ í˜• | ì €ì¥ì†Œ | ì´ìœ  |
|------------|--------|------|
| **ëŒ€í™” ë¡œê·¸** | Vector DB + RDS | ì„ë² ë”© ê²€ìƒ‰ + ì‹œê°„ìˆœ ì¡°íšŒ ë‘˜ ë‹¤ í•„ìš” |
| **ì‚¬ìš©ì ì„ í˜¸ë„** | Vector DB + Graph DB | ìœ ì‚¬ë„ ê²€ìƒ‰ + ê´€ê³„ ë¶„ì„ |
| **ì—¬í–‰ ì´ë ¥** | RDS + Vector DB | ì •í˜• ì¿¼ë¦¬ + ì˜ë¯¸ ê²€ìƒ‰ |
| **ë§›ì§‘/POI ì •ë³´** | ElasticSearch + Vector DB | ì „ë¬¸ ê²€ìƒ‰ + ì˜ë¯¸ ê²€ìƒ‰ |
| **GPS ê¶¤ì ** | Time-Series DB | ì‹œê³„ì—´ ë°ì´í„° íŠ¹í™” |
| **ì‚¬ì§„/ì˜ìƒ** | Object Store (S3) + Vector DB | íŒŒì¼ ì €ì¥ + ì´ë¯¸ì§€ ì„ë² ë”© |
| **ê´€ê³„ ë°ì´í„°** | Graph DB | ì¹œêµ¬, POI ì—°ê²°, ì¶”ì²œ ê²½ë¡œ |
| **ì‹¤ì‹œê°„ ìƒíƒœ** | Redis | ë¹ ë¥¸ ì½ê¸°/ì“°ê¸° |

### 2.2 êµ¬ì²´ì  ì €ì¥ ì „ëµ

#### 2.2.1 ëŒ€í™” ë¡œê·¸ (Dual Storage)

```python
class ConversationLogger:
    """ëŒ€í™”ë¥¼ ë‘ ê³³ì— ë™ì‹œ ì €ì¥"""
    
    async def log_conversation(self, user_id: str, message: dict):
        # 1. PostgreSQL (ì‹œê°„ìˆœ ì¡°íšŒìš©)
        await self.postgres.execute("""
            INSERT INTO conversations (user_id, role, content, timestamp)
            VALUES ($1, $2, $3, $4)
        """, user_id, message['role'], message['content'], datetime.now())
        
        # 2. Vector DB (ì˜ë¯¸ ê²€ìƒ‰ìš©)
        embedding = await self.embeddings.embed_query(message['content'])
        
        await self.pinecone.upsert(
            vectors=[{
                'id': f"{user_id}_{timestamp}",
                'values': embedding,
                'metadata': {
                    'user_id': user_id,
                    'role': message['role'],
                    'content': message['content'],
                    'timestamp': timestamp,
                    'trip_id': message.get('trip_id'),
                    'intent': message.get('intent')
                }
            }]
        )
    
    async def search_relevant_conversations(self, user_id: str, query: str, k: int = 5):
        """ì˜ë¯¸ ê¸°ë°˜ ëŒ€í™” ê²€ìƒ‰"""
        query_embedding = await self.embeddings.embed_query(query)
        
        results = await self.pinecone.query(
            vector=query_embedding,
            filter={'user_id': user_id},
            top_k=k,
            include_metadata=True
        )
        
        return results['matches']
```

#### 2.2.2 Graph DBë¡œ ê´€ê³„ í‘œí˜„

```python
# Neo4jë¡œ ë³µì¡í•œ ê´€ê³„ ì €ì¥

from neo4j import GraphDatabase

class TravelGraphDB:
    """ì—¬í–‰ ê´€ê³„ ê·¸ë˜í”„"""
    
    def __init__(self):
        self.driver = GraphDatabase.driver("bolt://localhost:7687")
    
    def create_user_preference_graph(self, user_id: str):
        """ì‚¬ìš©ì ì„ í˜¸ë„ ê·¸ë˜í”„ ìƒì„±"""
        
        with self.driver.session() as session:
            # ì‚¬ìš©ì ë…¸ë“œ
            session.run("""
                MERGE (u:User {id: $user_id})
            """, user_id=user_id)
            
            # ì¢‹ì•„í•˜ëŠ” ìŒì‹
            session.run("""
                MATCH (u:User {id: $user_id})
                MERGE (c:Cuisine {name: $cuisine})
                MERGE (u)-[:LIKES {strength: $strength}]->(c)
            """, user_id=user_id, cuisine="Italian", strength=0.9)
            
            # ë°©ë¬¸í•œ ì¥ì†Œ
            session.run("""
                MATCH (u:User {id: $user_id})
                MERGE (p:Place {id: $place_id})
                MERGE (u)-[:VISITED {
                    date: $date,
                    rating: $rating,
                    revisit: $revisit
                }]->(p)
            """, user_id=user_id, place_id="place_123", 
                 date="2024-01-01", rating=4.5, revisit=True)
    
    def find_similar_users(self, user_id: str):
        """ìœ ì‚¬í•œ ì‚¬ìš©ì ì°¾ê¸° (í˜‘ì—… í•„í„°ë§)"""
        
        with self.driver.session() as session:
            result = session.run("""
                MATCH (u1:User {id: $user_id})-[:LIKES]->(c:Cuisine)<-[:LIKES]-(u2:User)
                WHERE u1 <> u2
                WITH u2, COUNT(c) as common_cuisines
                ORDER BY common_cuisines DESC
                LIMIT 10
                RETURN u2.id, common_cuisines
            """, user_id=user_id)
            
            return [record for record in result]
    
    def recommend_based_on_friends(self, user_id: str):
        """ì¹œêµ¬ê°€ ì¢‹ì•„í•œ ê³³ ì¶”ì²œ"""
        
        with self.driver.session() as session:
            result = session.run("""
                MATCH (u:User {id: $user_id})-[:FRIEND]->(friend:User)
                      -[:VISITED {rating: r}]->(p:Place)
                WHERE r >= 4.0
                  AND NOT (u)-[:VISITED]->(p)
                WITH p, AVG(r) as avg_rating, COUNT(friend) as friend_count
                ORDER BY avg_rating DESC, friend_count DESC
                LIMIT 10
                RETURN p.id, p.name, avg_rating, friend_count
            """, user_id=user_id)
            
            return [record for record in result]
```

#### 2.2.3 ElasticSearchë¡œ ì „ë¬¸ ê²€ìƒ‰

```python
from elasticsearch import AsyncElasticsearch

class RestaurantSearchEngine:
    """ë§›ì§‘ ì „ë¬¸ ê²€ìƒ‰ ì—”ì§„"""
    
    def __init__(self):
        self.es = AsyncElasticsearch(['http://localhost:9200'])
    
    async def index_restaurant(self, restaurant: dict):
        """ë§›ì§‘ ì¸ë±ì‹±"""
        
        await self.es.index(
            index='restaurants',
            id=restaurant['id'],
            document={
                'name': restaurant['name'],
                'cuisine': restaurant['cuisine'],
                'location': restaurant['location'],  # Geo-point
                'description': restaurant['description'],
                'menu_items': restaurant['menu_items'],
                'reviews': restaurant['reviews'],
                'price_level': restaurant['price_level'],
                'rating': restaurant['rating']
            }
        )
    
    async def search(self, query: str, location: dict = None, filters: dict = None):
        """ë³µí•© ê²€ìƒ‰"""
        
        # 1. Full-text search (BM25)
        must_clauses = [
            {
                'multi_match': {
                    'query': query,
                    'fields': ['name^3', 'description^2', 'menu_items', 'reviews'],
                    'type': 'best_fields'
                }
            }
        ]
        
        # 2. ìœ„ì¹˜ í•„í„° (ìˆìœ¼ë©´)
        if location:
            must_clauses.append({
                'geo_distance': {
                    'distance': '2km',
                    'location': location
                }
            })
        
        # 3. ê¸°íƒ€ í•„í„°
        filter_clauses = []
        if filters:
            if 'cuisine' in filters:
                filter_clauses.append({'term': {'cuisine': filters['cuisine']}})
            if 'max_price' in filters:
                filter_clauses.append({'range': {'price_level': {'lte': filters['max_price']}}})
        
        body = {
            'query': {
                'bool': {
                    'must': must_clauses,
                    'filter': filter_clauses
                }
            },
            'sort': [
                {'_score': 'desc'},
                {'rating': 'desc'}
            ]
        }
        
        results = await self.es.search(index='restaurants', body=body)
        return results['hits']['hits']
```

---

## 3. ë©€í‹°ëª¨ë‹¬ RAG ì‹œìŠ¤í…œ

### 3.1 Hybrid Search (Vector + Keyword)

```python
class HybridRAG:
    """Vector Search + BM25ë¥¼ ê²°í•©í•œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰"""
    
    def __init__(self):
        self.vector_store = Pinecone(...)
        self.bm25_retriever = BM25Retriever(...)
        self.elastic = AsyncElasticsearch(...)
    
    async def retrieve(self, query: str, user_context: dict, k: int = 10):
        """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰"""
        
        # 1. Vector Search (ì˜ë¯¸ ê¸°ë°˜)
        query_embedding = await self.embeddings.embed_query(query)
        
        vector_results = await self.vector_store.query(
            vector=query_embedding,
            filter={
                'user_id': user_context['user_id'],
                # ìµœê·¼ 30ì¼ ëŒ€í™”ë§Œ
                'timestamp': {'$gte': datetime.now() - timedelta(days=30)}
            },
            top_k=k
        )
        
        # 2. BM25 Search (í‚¤ì›Œë“œ ê¸°ë°˜)
        bm25_results = await self.elastic.search(
            index='conversations',
            body={
                'query': {
                    'bool': {
                        'must': [
                            {'match': {'content': query}},
                            {'term': {'user_id': user_context['user_id']}}
                        ]
                    }
                }
            },
            size=k
        )
        
        # 3. Reciprocal Rank Fusion (RRF)
        fused_results = self.reciprocal_rank_fusion(
            [vector_results, bm25_results],
            k=60  # RRF íŒŒë¼ë¯¸í„°
        )
        
        return fused_results[:k]
    
    def reciprocal_rank_fusion(self, result_lists, k=60):
        """ì—¬ëŸ¬ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í†µí•©"""
        
        scores = {}
        
        for results in result_lists:
            for rank, doc in enumerate(results):
                doc_id = doc['id']
                # RRF ê³µì‹: 1 / (k + rank)
                scores[doc_id] = scores.get(doc_id, 0) + 1 / (k + rank + 1)
        
        # ì ìˆ˜ ìˆœ ì •ë ¬
        sorted_docs = sorted(scores.items(), key=lambda x: x[1], reverse=True)
        
        return sorted_docs
```

### 3.2 Contextual RAG (ì»¨í…ìŠ¤íŠ¸ ì¸ì‹)

```python
class ContextualRAG:
    """ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ë¥¼ ê³ ë ¤í•œ RAG"""
    
    async def retrieve_with_context(self, query: str, user_id: str):
        """ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ê²€ìƒ‰"""
        
        # 1. ì‚¬ìš©ì í˜„ì¬ ìƒíƒœ íŒŒì•…
        user_state = await self.get_user_state(user_id)
        
        # 2. ì¿¼ë¦¬ í™•ì¥ (Query Expansion)
        expanded_query = await self.expand_query(query, user_state)
        
        # 3. ê³„ì¸µì  ê²€ìƒ‰
        results = {
            # ê°œì¸ ëŒ€í™” (ê°€ì¥ ì¤‘ìš”)
            'personal': await self.search_personal_history(
                user_id, expanded_query, weight=0.5
            ),
            
            # ìœ ì‚¬ ì‚¬ìš©ì ê²½í—˜
            'collaborative': await self.search_similar_users(
                user_id, expanded_query, weight=0.3
            ),
            
            # ì¼ë°˜ ì§€ì‹ë² ì´ìŠ¤
            'general': await self.search_knowledge_base(
                expanded_query, weight=0.2
            )
        }
        
        # 4. ê°€ì¤‘ í†µí•©
        combined = self.weighted_fusion(results)
        
        return combined
    
    async def expand_query(self, query: str, user_state: dict):
        """ì‚¬ìš©ì ìƒíƒœë¡œ ì¿¼ë¦¬ í™•ì¥"""
        
        # í˜„ì¬ ì—¬í–‰ ì¤‘ì´ë©´ ëª©ì ì§€ ì¶”ê°€
        if user_state.get('active_trip'):
            destination = user_state['active_trip']['destination']
            query = f"{query} {destination}"
        
        # ì„ í˜¸ë„ ì¶”ê°€
        if user_state.get('food_preferences'):
            prefs = ', '.join(user_state['food_preferences'][:3])
            query = f"{query} (ì¢‹ì•„í•˜ëŠ” ìŒì‹: {prefs})"
        
        return query
```

### 3.3 Self-Reflective RAG (ìê¸° ê²€ì¦)

```python
class SelfReflectiveRAG:
    """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê²€ì¦í•˜ê³  ê°œì„ í•˜ëŠ” RAG"""
    
    async def retrieve_and_verify(self, query: str, user_id: str):
        """ê²€ìƒ‰ â†’ ê²€ì¦ â†’ ì¬ê²€ìƒ‰ ë£¨í”„"""
        
        max_iterations = 3
        
        for iteration in range(max_iterations):
            # 1. ê²€ìƒ‰
            docs = await self.hybrid_search(query, user_id)
            
            # 2. ê´€ë ¨ì„± ê²€ì¦
            relevance_scores = await self.verify_relevance(query, docs)
            
            # 3. ì¶©ë¶„íˆ ê´€ë ¨ì„± ìˆìœ¼ë©´ ì¢…ë£Œ
            if all(score > 0.7 for score in relevance_scores):
                return docs
            
            # 4. ì¿¼ë¦¬ ê°œì„ 
            query = await self.improve_query(query, docs, relevance_scores)
        
        return docs
    
    async def verify_relevance(self, query: str, docs: list):
        """LLMìœ¼ë¡œ ê´€ë ¨ì„± ê²€ì¦"""
        
        prompt = f"""
        Query: {query}
        
        Documents:
        {self.format_docs(docs)}
        
        For each document, rate relevance 0.0-1.0:
        """
        
        response = await self.llm.ainvoke(prompt)
        scores = self.parse_scores(response)
        
        return scores
    
    async def improve_query(self, original_query: str, docs: list, scores: list):
        """ì¿¼ë¦¬ ê°œì„ """
        
        # ë‚®ì€ ì ìˆ˜ ë¬¸ì„œ ë¶„ì„
        low_score_docs = [doc for doc, score in zip(docs, scores) if score < 0.5]
        
        prompt = f"""
        Original query: {original_query}
        
        Retrieved documents were not relevant enough.
        Low-relevance documents:
        {self.format_docs(low_score_docs)}
        
        Suggest an improved query that would retrieve more relevant information.
        """
        
        improved = await self.llm.ainvoke(prompt)
        
        return improved
```

---

## 4. ì‹¤ì‹œê°„ ë°ì´í„° íŒŒì´í”„ë¼ì¸

### 4.1 Streaming Pipeline

```python
from kafka import KafkaProducer, KafkaConsumer
import asyncio

class RealTimeDataPipeline:
    """ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì§‘ â†’ ì²˜ë¦¬ â†’ ì €ì¥"""
    
    def __init__(self):
        self.kafka_producer = KafkaProducer(
            bootstrap_servers=['localhost:9092'],
            value_serializer=lambda v: json.dumps(v).encode('utf-8')
        )
    
    async def process_user_event(self, event: dict):
        """ì‚¬ìš©ì ì´ë²¤íŠ¸ ì‹¤ì‹œê°„ ì²˜ë¦¬"""
        
        # 1. Kafkaë¡œ ì „ì†¡ (ë¹„ë™ê¸° ì²˜ë¦¬)
        self.kafka_producer.send('user-events', event)
        
        # 2. ì¤‘ìš” ì´ë²¤íŠ¸ëŠ” ì¦‰ì‹œ ì²˜ë¦¬
        if event['type'] in ['gps_update', 'urgent_request']:
            await self.process_immediately(event)
    
    async def consume_and_store(self):
        """Kafka ì†Œë¹„ â†’ ì €ì¥"""
        
        consumer = KafkaConsumer(
            'user-events',
            bootstrap_servers=['localhost:9092'],
            auto_offset_reset='earliest'
        )
        
        for message in consumer:
            event = json.loads(message.value)
            
            # ë³‘ë ¬ ì €ì¥
            await asyncio.gather(
                # RDS
                self.store_to_rds(event),
                # Vector DB (ì„ë² ë”©)
                self.store_to_vector_db(event),
                # Cache ì—…ë°ì´íŠ¸
                self.update_cache(event)
            )
```

### 4.2 Change Data Capture (CDC)

```python
from debezium import DebeziumClient

class DatabaseSyncService:
    """RDS ë³€ê²½ì‚¬í•­ì„ ìë™ìœ¼ë¡œ Vector DBì— ë™ê¸°í™”"""
    
    def __init__(self):
        self.debezium = DebeziumClient(...)
        self.vector_store = Pinecone(...)
    
    async def sync_on_change(self):
        """RDS ë³€ê²½ ê°ì§€ â†’ Vector DB ì—…ë°ì´íŠ¸"""
        
        async for change in self.debezium.stream():
            if change['table'] == 'restaurants':
                if change['operation'] == 'INSERT':
                    await self.add_to_vector_db(change['data'])
                
                elif change['operation'] == 'UPDATE':
                    await self.update_vector_db(change['data'])
                
                elif change['operation'] == 'DELETE':
                    await self.remove_from_vector_db(change['id'])
```

---

## 5. ìºì‹± & ì„±ëŠ¥ ìµœì í™”

### 5.1 Multi-Layer Cache

```python
class MultiLayerCache:
    """3ë‹¨ê³„ ìºì‹± ì „ëµ"""
    
    def __init__(self):
        # L1: In-memory (ê°€ì¥ ë¹ ë¦„)
        self.l1_cache = {}
        
        # L2: Redis (ë¹ ë¦„)
        self.l2_cache = redis.Redis(...)
        
        # L3: PostgreSQL (ëŠë¦¼)
        self.l3_db = PostgreSQL(...)
    
    async def get(self, key: str):
        """ê³„ì¸µì  ì¡°íšŒ"""
        
        # L1 í™•ì¸
        if key in self.l1_cache:
            return self.l1_cache[key]
        
        # L2 í™•ì¸
        value = await self.l2_cache.get(key)
        if value:
            self.l1_cache[key] = value  # L1ì— ìŠ¹ê²©
            return value
        
        # L3 í™•ì¸
        value = await self.l3_db.get(key)
        if value:
            await self.l2_cache.set(key, value, ex=3600)  # L2ì— ì €ì¥
            self.l1_cache[key] = value  # L1ì—ë„ ì €ì¥
            return value
        
        return None
    
    async def set(self, key: str, value: any, ttl: int = 3600):
        """ëª¨ë“  ë ˆì´ì–´ì— ì €ì¥"""
        
        # L1
        self.l1_cache[key] = value
        
        # L2
        await self.l2_cache.set(key, value, ex=ttl)
        
        # L3 (ì„ íƒì )
        if self.should_persist(key):
            await self.l3_db.set(key, value)
```

### 5.2 ì„ ì œì  ìºì‹±

```python
class PredictiveCaching:
    """ì‚¬ìš©ì í–‰ë™ ì˜ˆì¸¡ ê¸°ë°˜ ì„ ì œì  ìºì‹±"""
    
    async def predict_and_cache(self, user_id: str):
        """ë‹¤ìŒì— í•„ìš”í•  ë°ì´í„° ë¯¸ë¦¬ ë¡œë“œ"""
        
        # 1. ì‚¬ìš©ì íŒ¨í„´ ë¶„ì„
        patterns = await self.analyze_user_patterns(user_id)
        
        # 2. ë‹¤ìŒ ì•¡ì…˜ ì˜ˆì¸¡
        predicted_actions = self.ml_model.predict(patterns)
        
        # 3. ë¯¸ë¦¬ ìºì‹±
        for action in predicted_actions:
            if action == 'search_restaurant':
                # ì£¼ë³€ ë§›ì§‘ ë¯¸ë¦¬ ë¡œë“œ
                await self.preload_nearby_restaurants(user_id)
            
            elif action == 'check_route':
                # ê²½ë¡œ ì •ë³´ ë¯¸ë¦¬ ê³„ì‚°
                await self.precompute_routes(user_id)
```

---

## 6. ê°œì¸ì •ë³´ & ë³´ì•ˆ

### 6.1 ë°ì´í„° ì•”í˜¸í™”

```python
from cryptography.fernet import Fernet

class SecureDataManager:
    """ë¯¼ê° ì •ë³´ ì•”í˜¸í™”"""
    
    def __init__(self):
        self.cipher = Fernet(Fernet.generate_key())
    
    async def store_sensitive_data(self, user_id: str, data: dict):
        """ë¯¼ê° ì •ë³´ ì•”í˜¸í™” ì €ì¥"""
        
        # ì•”í˜¸í™”
        encrypted = {
            'credit_card': self.cipher.encrypt(data['credit_card'].encode()),
            'phone': self.cipher.encrypt(data['phone'].encode()),
        }
        
        # Vector DBì—ëŠ” ì•”í˜¸í™”ëœ ìƒíƒœë¡œ
        await self.vector_store.upsert({
            'user_id': user_id,
            'encrypted_data': encrypted
        })
    
    def decrypt(self, encrypted_data: bytes) -> str:
        """ë³µí˜¸í™”"""
        return self.cipher.decrypt(encrypted_data).decode()
```

### 6.2 GDPR ì¤€ìˆ˜ (ìŠí˜€ì§ˆ ê¶Œë¦¬)

```python
class GDPRCompliance:
    """ì‚¬ìš©ì ë°ì´í„° ì™„ì „ ì‚­ì œ"""
    
    async def delete_user_data(self, user_id: str):
        """ëª¨ë“  ì €ì¥ì†Œì—ì„œ ì‚­ì œ"""
        
        await asyncio.gather(
            # Vector DB
            self.vector_store.delete(filter={'user_id': user_id}),
            
            # RDS
            self.postgres.execute("DELETE FROM users WHERE user_id = $1", user_id),
            self.postgres.execute("DELETE FROM trips WHERE user_id = $1", user_id),
            
            # Graph DB
            self.neo4j.run("MATCH (u:User {id: $user_id}) DETACH DELETE u", user_id=user_id),
            
            # Cache
            self.redis.delete(f"user:{user_id}:*"),
            
            # ElasticSearch
            self.elastic.delete_by_query(
                index='*',
                body={'query': {'term': {'user_id': user_id}}}
            )
        )
```

---

## ğŸ¯ ìµœì¢… ê¶Œì¥ ì•„í‚¤í…ì²˜

```python
class TravelOSDataLayer:
    """í†µí•© ë°ì´í„° ë ˆì´ì–´"""
    
    def __init__(self):
        # 1. í•µì‹¬ ì €ì¥ì†Œ
        self.postgres = PostgreSQL(...)      # ì •í˜• ë°ì´í„°
        self.pinecone = Pinecone(...)         # ë²¡í„° ê²€ìƒ‰
        self.neo4j = Neo4j(...)               # ê´€ê³„ ë°ì´í„°
        self.elastic = Elasticsearch(...)     # ì „ë¬¸ ê²€ìƒ‰
        
        # 2. ì„±ëŠ¥ ë ˆì´ì–´
        self.redis = Redis(...)               # ìºì‹œ
        self.influxdb = InfluxDB(...)         # ì‹œê³„ì—´
        
        # 3. RAG ì‹œìŠ¤í…œ
        self.hybrid_rag = HybridRAG(...)
        self.contextual_rag = ContextualRAG(...)
        
        # 4. ì‹¤ì‹œê°„ íŒŒì´í”„ë¼ì¸
        self.kafka = KafkaPipeline(...)
        
    async def query(self, query: str, user_id: str, context: dict):
        """Unified Query Interface"""
        
        # 1. ìºì‹œ í™•ì¸
        cached = await self.redis.get(f"query:{user_id}:{hash(query)}")
        if cached:
            return cached
        
        # 2. í•˜ì´ë¸Œë¦¬ë“œ RAG
        retrieved_docs = await self.hybrid_rag.retrieve(
            query, 
            user_context=context
        )
        
        # 3. Graph ë³´ê°• (ê´€ê³„ ì •ë³´)
        graph_context = await self.neo4j.get_related_context(user_id)
        
        # 4. ê²°ê³¼ í†µí•©
        result = self.synthesize(retrieved_docs, graph_context)
        
        # 5. ìºì‹±
        await self.redis.set(f"query:{user_id}:{hash(query)}", result, ex=3600)
        
        return result
```

---

## âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸

**ì¦‰ì‹œ êµ¬í˜„:**
- [x] PostgreSQL (ì •í˜• ë°ì´í„°)
- [x] Pinecone (ë²¡í„° ê²€ìƒ‰)
- [x] Redis (ìºì‹±)

**Phase 2:**
- [ ] Neo4j (ê´€ê³„ ë°ì´í„°)
- [ ] ElasticSearch (ì „ë¬¸ ê²€ìƒ‰)
- [ ] Kafka (ì‹¤ì‹œê°„ íŒŒì´í”„ë¼ì¸)

**Phase 3:**
- [ ] InfluxDB (GPS ê¶¤ì )
- [ ] S3 (ì‚¬ì§„/ì˜ìƒ)
- [ ] CDC (ìë™ ë™ê¸°í™”)

---

**ì´ ì•„í‚¤í…ì²˜ë¡œ Travel OSëŠ” ì§„ì§œ ìš´ì˜ì²´ì œê¸‰ ë°ì´í„° ì²˜ë¦¬ ëŠ¥ë ¥ì„ ê°–ì¶”ê²Œ ë©ë‹ˆë‹¤!** ğŸš€

"""LangGraph API Router - í”„ë¡ íŠ¸ì—”ë“œ ì—°ê²°"""
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from typing import Optional, List, Dict, Any
from agents.graph import travel_agent_graph

router = APIRouter(
    prefix="/api/langgraph",
    tags=["langgraph"],
    responses={404: {"description": "Not found"}},
)


class ChatRequest(BaseModel):
    """ì±„íŒ… ìš”ì²­ ëª¨ë¸"""
    message: str
    conversation_history: Optional[List[Dict[str, str]]] = []
    preferred_character: Optional[str] = "otter"  # otter ë˜ëŠ” kkachil


class ChatResponse(BaseModel):
    """ì±„íŒ… ì‘ë‹µ ëª¨ë¸"""
    response: str
    intent: str
    data: Optional[Dict[str, Any]] = None


@router.post("/chat", response_model=ChatResponse)
async def langgraph_chat(request: ChatRequest):
    """
    LangGraph ë©€í‹°ì—ì´ì „íŠ¸ ì±—ë´‡ ì—”ë“œí¬ì¸íŠ¸
    
    Features:
    - Orchestratorê°€ ì˜ë„ íŒŒì•… (restaurant/region/itinerary/chat)
    - ReAct Agent ìë™ Tool ì„ íƒ
    - ì—‰ëš±ìˆ˜ë‹¬ ìºë¦­í„° ë ˆì´ì–´ ì ìš©
    - ìºì‹±ìœ¼ë¡œ ë¹ ë¥¸ ì‘ë‹µ (5ë¶„ TTL)
    
    Args:
        request: ChatRequest (message, conversation_history)
        
    Returns:
        ChatResponse (response, intent, data)
    """
from core.cache import langgraph_cache
from core.workflow import create_travel_graph
import logging

# Initialize Logger
logger = logging.getLogger(__name__)

# [Optimization] Lazy Global Cache
_WORKFLOW_CACHE = None

def get_workflow():
    global _WORKFLOW_CACHE
    if _WORKFLOW_CACHE is None:
        print("ğŸš€ [LangGraph] First-time Compilation...")
        _WORKFLOW_CACHE = create_travel_graph()
        print("âœ… [LangGraph] Workflow Compiled and Cached.")
    return _WORKFLOW_CACHE

@router.post("/chat", response_model=ChatResponse)
async def langgraph_chat(request: ChatRequest):
    """
    LangGraph ë©€í‹°ì—ì´ì „íŠ¸ ì±—ë´‡ ì—”ë“œí¬ì¸íŠ¸
    """
    try:
        print("\n" + "=" * 80)
        print(f"ğŸ¤– [LangGraph API] ìƒˆ ìš”ì²­ ìˆ˜ì‹ ")
        print(f"ğŸ“ ë©”ì‹œì§€: {request.message}")
        print("=" * 80)
        
        # ìºì‹œ í™•ì¸
        cached_result = langgraph_cache.get(request.message)
        if cached_result:
            print(f"âš¡ [ìºì‹œ HIT] ì €ì¥ëœ ì‘ë‹µ ë°˜í™˜")
            print("=" * 80 + "\n")
            return ChatResponse(**cached_result)
        
        print(f"âŒ [ìºì‹œ MISS] LangGraph ì‹¤í–‰ ì‹œì‘...")
        
        # [New] Get Cached Workflow
        app_workflow = get_workflow()
        
        # [New] LangGraph Execution with updated State
        initial_state = {
            "user_input": request.message,
            "messages": [{"role": "user", "content": request.message}],
            "user_id": "test-user", # Placeholder
            "detected_language": "ko"
        }
        
        # Use Cached Workflow Instance
        result = await app_workflow.ainvoke(initial_state)
        
        print(f"\nâœ… [LangGraph ì™„ë£Œ]")
        
        # Extract results from new State structure
        last_message = result.get("messages", [])[-1]["content"] if result.get("messages") else "ì‘ë‹µì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        intent = result.get("intent_type") or result.get("search_mode") or "chat"
        
        daily_plans = result.get("daily_plans")
        
        # Format for Frontend
        response_data = {
            "response": last_message,
            "intent": intent,
            "data": {
                "daily_plans": daily_plans,
                "budget": result.get("budget_info"),
                "weather": result.get("weather_info")
            }
        }
        
        print(f"ğŸ¯ ì˜ë„: {intent}")
        print(f"ğŸ’¬ ì‘ë‹µ: {last_message[:100]}...")
        print("=" * 80 + "\n")
        
        # ìºì‹œì— ì €ì¥
        langgraph_cache.set(request.message, response_data, intent)
        
        return ChatResponse(**response_data)
        
    except Exception as e:
        import traceback
        error_msg = f"LangGraph Error: {str(e)}\n{traceback.format_exc()}"
        print(f"âŒ [LangGraph API] Error: {error_msg}")
        
        # Return error as valid response for debugging
        return ChatResponse(
            response="ì£„ì†¡í•´ìš”, ë‚´ë¶€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”. (Debug Mode)",
            intent="error",
            data={"error": error_msg}
        )


@router.get("/health")
async def health_check():
    """í—¬ìŠ¤ ì²´í¬"""
    return {
        "status": "healthy",
        "service": "LangGraph Multi-Agent System",
        "character": "ì—‰ëš±ìˆ˜ë‹¬ (Eongddong Otter)"
    }

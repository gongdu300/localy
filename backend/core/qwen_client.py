"""
Remote Qwen Client
- KAMP ì»´í“¨í„°(ë˜ëŠ” ì›ê²© ì„œë²„)ì˜ vLLM API í˜¸ì¶œ
- uses openai python client library for better compatibility
"""
import os
import logging
import json
from dotenv import load_dotenv
from openai import OpenAI

# ìºë¦­í„° ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ import
import sys
from pathlib import Path
# agents í´ë”ë¥¼ import ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent / "agents"))
from character_system_prompts import KKACHIL_SYSTEM_PROMPT, SUNDONG_SYSTEM_PROMPT, EONGDDONG_SYSTEM_PROMPT

load_dotenv(override=True)
logger = logging.getLogger(__name__)

# [Refactor] ì „ì—­ ë³€ìˆ˜ ì œê±°í•˜ê³  __init__ì—ì„œ ë¡œë“œ

class QwenStyleService:
    def __init__(self):
        # .env ì¬ë¡œë“œ (í™•ì‹¤í•˜ê²Œ ìµœì‹ ê°’ ë°˜ì˜)
        load_dotenv(override=True)
        
        # URL ë¡œë“œ (ê¸°ë³¸ê°’ ì„¤ì •)
        self.base_url = os.getenv("KAMP_QWEN_URL", "https://yojgf-125-6-60-4.a.free.pinggy.link/v1")
        
        # URL ë³´ì •: /chat/completionsê°€ ë¶™ì–´ìˆìœ¼ë©´ ë–¼ì–´ëƒ„
        if "/chat/completions" in self.base_url:
            self.base_url = self.base_url.replace("/chat/completions", "")
        
        # /v1 ë¡œ ëë‚˜ëŠ”ì§€ í™•ì¸ (OpenAI Client ìš”êµ¬ì‚¬í•­)
        if not self.base_url.endswith("/v1"):
            self.base_url = self.base_url.rstrip("/") + "/v1"
            
        logger.info(f"Qwen Client Initialized (Base: {self.base_url})")
        
        self.client = OpenAI(
            base_url=self.base_url,
            api_key="not-needed",
            default_headers={"Bypass-Tunnel-Reminder": "true"},
            timeout=30.0
        )

    def apply_character_style(self, character: str, core_output: dict, detected_language: str = "ko") -> dict:
        """
        ì›ê²© Qwen APIë¥¼ í˜¸ì¶œí•˜ì—¬ ìºë¦­í„° ë§íˆ¬ë¡œ ë³€í™˜
        - OpenAI SDK ì‚¬ìš©
        - detected_language: "ko" or "en"
        """
        prompt = self._build_character_prompt(character, core_output, detected_language)
        
        try:
            # 1. ëª¨ë¸ ID ë™ì  ì¡°íšŒ
            models = self.client.models.list()
            if not models.data:
                logger.warning("No models found on server, using default 'Qwen/Qwen2.5-14B-Instruct'")
                model_id = "Qwen/Qwen2.5-14B-Instruct"
            else:
                model_id = models.data[0].id

            # 2. Chat Completion ìš”ì²­
            response = self.client.chat.completions.create(
                model=model_id,
                messages=[
                    {"role": "system", "content": "You are a helpful assistant."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=2000 # [ìˆ˜ì •] ì„œë²„ ìš©ëŸ‰(4096) í™•ë³´ë¡œ ëŒ€í­ ì¦ê°€!
            )
            
            generated_text = response.choices[0].message.content
            
            return {
                "character": character,
                "text": generated_text,
                "ui_hints": core_output.get("ui_hints", {})
            }
            
        except Exception as e:
            logger.error(f"Qwen API Call Failed (OpenAI Client): {e}")
            # ì‹¤íŒ¨ ì‹œ Fallback: ë³€í™˜ ì—†ì´ ì›ë³¸ ë°˜í™˜
            return {
                "character": character,
                "text": f"(ë§íˆ¬ ë³€í™˜ ì‹¤íŒ¨) {json.dumps(core_output, ensure_ascii=False)}",
                "ui_hints": core_output.get("ui_hints", {})
            }

    def _build_character_prompt(self, character: str, core_output: dict, detected_language: str = "ko") -> str:
        """ìºë¦­í„° í”„ë¡¬í”„íŠ¸ ìƒì„± (ì–¸ì–´ë³„ ë¶„ê¸°)"""
        
        traits_ko = {
            "cat": "ê¹Œì¹ ëƒ¥ì´ - ë˜‘ë¶€ëŸ¬ì§€ê³  ì§ì„¤ì , ~ëƒ¥ ë§íˆ¬, ë„ë„í•˜ì§€ë§Œ ì‹¤ì† ì±™ê¹€",
            "dog": "ìˆœë‘¥ë©ë©ì´ - ë‹¤ì •í•˜ê³  ì¹œê·¼í•¨, ~ë© ë§íˆ¬, í•­ìƒ ì‘ì›í•˜ê³  ê²©ë ¤",
            "otter": "ì—‰ëš±ìˆ˜ë‹¬ - ë°œë„í•˜ê³  ì—‰ëš±í•¨, ~ë‹¬ ë§íˆ¬, ì¬ì¹˜ìˆê³  ì°½ì˜ì "
        }
        
        traits_en = {
            "cat": "Kkachil Cat - Sharp and straightforward, ends sentences with 'nyaa', proud but practical",
            "dog": "Sundong Dog - Warm and friendly, ends sentences with 'woof', always supportive",
            "otter": "Eongddong Otter - Quirky and playful, ends sentences with 'dal', creative and witty"
        }
        
        # [ìµœì í™”] ì…ë ¥ ë°ì´í„°ê°€ ë„ˆë¬´ ë³µì¡í•˜ë©´ ëª¨ë¸ì´ íš¡ì„¤ìˆ˜ì„¤í•¨.
        # í•µì‹¬ ì •ë³´ ìœ„ì£¼ë¡œ ê¹”ë”í•˜ê²Œ ì •ë¦¬í•´ì„œ ì „ë‹¬ (í† í° ì ˆì•½ + í’ˆì§ˆ í–¥ìƒ)
        minified_data = self._minify_context(core_output)
        
        # [New] Detect Prompt Type
        is_simple_search = False
        is_gallery = False
        
        # Check if minified data indicates simple search or gallery
        if minified_data.get("gallery"):
            is_gallery = True
        elif not minified_data.get("plan") and minified_data.get("shopping"):
             is_simple_search = True # Only shopping
        elif minified_data.get("plan"):
             # Check if plan day 1 has 'places' but no 'day' logic (implied by previous fix users saw)
             # But easier is to check the structure.
             pass

        if detected_language == "en":
            # English prompt
            trait_desc = traits_en.get(character, "friendly guide")
            
            task_instruction = "Review the travel itinerary data below and explain it to the user in detail."
            if is_gallery:
                task_instruction = "The user asked for photos. Introduce the photo gallery enthusiastically! **IMPORTANT: You MUST VALIDLY display at least 3 photos using markdown sequence: `![Name](URL)`**."
            elif is_simple_search:
                task_instruction = "The user asked for specific recommendations. Introduce these places enthusiastically!"
            
            return f"""
You are a {trait_desc} character.
{task_instruction}

**Rules:**
1. Deliver information (places) accurately.
2. Maintain your character's unique speech pattern throughout and use emojis generously.
3. If it's a list, introduce 3-4 key spots. If it's an itinerary, explain the flow.
4. **For Gallery Mode, you MUST output the image links in Markdown format.**
5. **IMPORTANT: Respond in ENGLISH only!**

**Input Data (Summary):**
```json
{json.dumps(minified_data, ensure_ascii=False, indent=2)}
```
"""
        else:
            # Korean prompt
            trait_desc = traits_ko.get(character, "ì¹œì ˆí•œ ê°€ì´ë“œ")
            
            task_instruction = "ì•„ë˜ ì—¬í–‰ ì¼ì • ìš”ì•½ ë°ì´í„°ë¥¼ ë³´ê³ , ì‚¬ìš©ìì—ê²Œ ìƒì„¸í•˜ê³  ì¬ë¯¸ìˆê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”."
            if is_gallery:
                task_instruction = "ì‚¬ìš©ìê°€ ì‚¬ì§„ì„ ìš”ì²­í–ˆìŠµë‹ˆë‹¤. ê°¤ëŸ¬ë¦¬ì— ìˆëŠ” ì‚¬ì§„ë“¤ì„ ì‹ ë‚˜ê²Œ ì†Œê°œí•´ì£¼ì„¸ìš”! **ì¤‘ìš”: ë°˜ë“œì‹œ ë§ˆí¬ë‹¤ìš´ ì´ë¯¸ì§€ ë¬¸ë²• `![ì¥ì†Œëª…](ì´ë¯¸ì§€URL)`ì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ì§„ 3~5ì¥ì„ ì§ì ‘ ë³´ì—¬ì£¼ì„¸ìš”!**"
            elif is_simple_search:
                task_instruction = "ì‚¬ìš©ìê°€ íŠ¹ì • ì¥ì†Œ(ë§›ì§‘/ì‡¼í•‘ ë“±) ì¶”ì²œì„ ìš”ì²­í–ˆìŠµë‹ˆë‹¤. ì´ ì¥ì†Œë“¤ì„ ë§¤ë ¥ì ìœ¼ë¡œ ì†Œê°œí•´ì£¼ì„¸ìš”! 'ì¼ì •'ì´ë¼ëŠ” ë§ì€ ì“°ì§€ ë§ˆì„¸ìš”."

            return f"""
ë‹¹ì‹ ì€ {trait_desc} ìºë¦­í„°ì…ë‹ˆë‹¤.
{task_instruction}

**ê·œì¹™:**
1. ì •ë³´(ì¥ì†Œ)ëŠ” ì •í™•íˆ ì „ë‹¬í•˜ì„¸ìš”.
2. ê° ì¥ì†Œì˜ ë§¤ë ¥(ë§›, í’ê²½, ë¶„ìœ„ê¸°)ì„ ìƒìƒë ¥ì„ ë°œíœ˜í•´ ì•„ì£¼ í’ë¶€í•˜ê³  ìˆ˜ë‹¤ìŠ¤ëŸ½ê²Œ ë¬˜ì‚¬í•˜ì„¸ìš”.
3. ìºë¦­í„° íŠ¹ìœ ì˜ ë§íˆ¬(~ë‹¬, ~ëƒ¥, ~ë©)ë¥¼ ëê¹Œì§€ ìœ ì§€í•˜ë©°, ì´ëª¨ì§€ë„ ë“¬ë¿ ì“°ì„¸ìš”.
4. **ê°¤ëŸ¬ë¦¬ ëª¨ë“œì¼ ê²½ìš°, ë°˜ë“œì‹œ ì œê³µëœ ì´ë¯¸ì§€ URLì„ ì‚¬ìš©í•˜ì—¬ ë§ˆí¬ë‹¤ìš´ ì´ë¯¸ì§€(`![ì„¤ëª…](ì£¼ì†Œ)`)ë¥¼ ë³¸ë¬¸ì— í¬í•¨í•˜ì„¸ìš”.**
5. ë‹¨ìˆœ ì¶”ì²œì¼ ê²½ìš° "1ì¼ì°¨" ê°™ì€ ë§ì€ ë¹¼ê³ , ìì—°ìŠ¤ëŸ½ê²Œ ì¥ì†Œë¥¼ ë‚˜ì—´í•˜ë©° ì¶”ì²œí•´ì£¼ì„¸ìš”.
6. **ì¤‘ìš”: ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”!**

**ì…ë ¥ ë°ì´í„°(ìš”ì•½):**
```json
{json.dumps(minified_data, ensure_ascii=False, indent=2)}
```
"""

    def _minify_context(self, core_output: dict) -> dict:
        """í•µì‹¬ ë°ì´í„°ë§Œ ì¶”ì¶œ (ëª¨ë¸ í˜¼ë€ ë°©ì§€ìš©)"""
        plan = core_output.get("plan", {})
        simplified_plan = {}
        
        if plan:
            # ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜ (ê°€ë” ë¦¬ìŠ¤íŠ¸ë¡œ ì˜¬ ë•Œê°€ ìˆìŒ)
            if isinstance(plan, list):
                # ë¦¬ìŠ¤íŠ¸ë¼ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ê±°ë‚˜ ë³€í™˜ ë¡œì§ í•„ìš”.
                pass
            
            # [Fix] Handle special search result structures
            # 1. Simple List Mode (items directly in day 1)
            # Structure: {"1": {"day_number": 1, "items": [...]}}
            # 2. Gallery Mode
            # Structure: {"gallery_mode": True, "data": {...}}
            
            # Check for Gallery Mode first
            if plan.get("gallery_mode"):
                # ê°¤ëŸ¬ë¦¬ ëª¨ë“œëŠ” ë³„ë„ 'gallery' í‚¤ë¡œ ì²˜ë¦¬ë˜ë¯€ë¡œ planì—ì„œëŠ” ë¬´ì‹œí•˜ê±°ë‚˜ ìš”ì•½ë§Œ
                simplified_plan["note"] = "User requested photos. See gallery section."
                
            else:
                for day_key, day_data in plan.items():
                    if not isinstance(day_data, dict): continue
                    
                    # [Fix] DailyItinerary ìŠ¤í‚¤ë§ˆëŠ” 'items' í•„ë“œë¥¼ ì‚¬ìš©í•¨ (places ì•„ë‹˜)
                    places = day_data.get("items", []) 
                    simple_places = []
                    for p in places:
                        # ì¥ì†Œì˜ í•µì‹¬ë§Œ ì¶”ì¶œ
                        # ItineraryItem ìŠ¤í‚¤ë§ˆ: place_name, category, notes ë“±
                        sp = {
                            "name": p.get("place_name") or p.get("name"), # í•„ë“œëª… í˜¸í™˜ì„±
                            "category": p.get("category"),
                            "time": p.get("time") # ì‹œê°„ ì •ë³´ ì¶”ê°€
                        }
                        if p.get("notes"): 
                            sp["desc"] = p.get("notes")
                        simple_places.append(sp)
                        
                    simplified_plan[day_key] = {
                        "day": day_data.get("day_number"),
                        "places": simple_places
                    }

        # [New] Minified Shopping Results
        shopping_raw = core_output.get("shopping", [])
        shopping_summary = []
        if shopping_raw and isinstance(shopping_raw, list):
            for s in shopping_raw[:5]:  # Top 5 only
                shopping_summary.append({
                    "name": s.get("name"),
                    "rating": s.get("rating"),
                    "type": s.get("types", [])[:2] # types simplified
                })
        
        # [New] Minified Gallery Results
        gallery_raw = core_output.get("gallery", {})
        gallery_summary = []
        
        if gallery_raw and isinstance(gallery_raw, dict):
            # [Fix] Extract actual results if nested
            real_gallery_data = gallery_raw.get("gallery_results", gallery_raw)
            
            # If still wrapped or empty, handle gracefully
            if isinstance(real_gallery_data, dict):
                 for place_name, urls in list(real_gallery_data.items())[:5]:
                    # [Fix] ì´ë¯¸ì§€ URLë„ í•¨ê»˜ ì „ë‹¬ (ë§ˆí¬ë‹¤ìš´ ì¶œë ¥ìš©)
                    first_url = urls[0] if urls and isinstance(urls, list) else ""
                    gallery_summary.append({
                        "name": place_name,
                        "image": first_url
                    })

        minified = {
            "destination": core_output.get("destination", "ì—¬í–‰ì§€"),
            "plan": simplified_plan,
            "shopping": shopping_summary, # [New]
            "gallery": gallery_summary,   # [New]
            "weather": core_output.get("weather", "ì •ë³´ ì—†ìŒ")
        }
        
        # [Debug] Log minified data to help debug detailed prompt issues
        logger.info(f"ğŸ§© Minified Context for Qwen:\n{json.dumps(minified, ensure_ascii=False, indent=2)}")
        
        return minified
    def apply_general_chat(self, character: str, user_input: str, detected_language: str = "ko") -> str:
        """
        ì¼ë°˜ ëŒ€í™” ëª¨ë“œ
        - ì˜ì–´: GPT-4 ì§ì ‘ ì‚¬ìš©
        - í•œêµ­ì–´: Qwen ìºë¦­í„° ëª¨ë¸ ì‚¬ìš©
        """
        
        logger.info(f"ğŸ” [DEBUG] detected_language='{detected_language}', type={type(detected_language)}")
        
        if detected_language == "en":
            # ì˜ì–´ëŠ” GPT-4ë¡œ ì§ì ‘ ì‘ë‹µ
            import openai
            import os
            
            character_traits = {
                "cat": "Kkachil Cat - sharp, straightforward, ends with 'nyaa'",
                "dog": "Sundong Dog - warm, friendly, ends with 'woof'",
                "otter": "Eongddong Otter - quirky, playful, ends with 'dal'"
            }
            
            trait = character_traits.get(character, character_traits["otter"])
            
            try:
                openai_client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
                
                response = openai_client.chat.completions.create(
                    model="gpt-4",
                    messages=[
                        {"role": "system", "content": f"You are {trait}. Be helpful and friendly. Use emojis. Keep responses concise and natural."},
                        {"role": "user", "content": user_input}
                    ],
                    temperature=0.7,
                    max_tokens=500
                )
                
                return response.choices[0].message.content
                
            except Exception as e:
                logger.error(f"GPT-4 Chat Failed: {e}")
                return "Sorry, I'm having trouble right now, dal... ğŸ˜¿"
            
        else:
            # í•œêµ­ì–´ëŠ” ê¸°ì¡´ Qwen ì‚¬ìš©
            system_prompts_ko = {
                "cat": KKACHIL_SYSTEM_PROMPT + "\n\n**ì¤‘ìš”: ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”!**",
                "dog": SUNDONG_SYSTEM_PROMPT + "\n\n**ì¤‘ìš”: ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”!**",
                "otter": EONGDDONG_SYSTEM_PROMPT + "\n\n**ì¤‘ìš”: ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”!**"
            }
            
            system_prompt = system_prompts_ko.get(character, EONGDDONG_SYSTEM_PROMPT)
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_input}
            ]
        
            try:
                # 1. ëª¨ë¸ ID ë™ì  ì¡°íšŒ
                models = self.client.models.list()
                if not models.data:
                    model_id = "Qwen/Qwen2.5-14B-Instruct"
                else:
                    model_id = models.data[0].id

                # 2. Chat Completion ìš”ì²­
                response = self.client.chat.completions.create(
                    model=model_id,
                    messages=messages,
                    temperature=0.7,
                    max_tokens=1000
                )
                
                return response.choices[0].message.content
                
            except Exception as e:
                logger.error(f"Qwen Chat Failed: {e}")
                return "ì£„ì†¡í•´ìš”, ì„œë²„ ì—°ê²°ì´ ì›í™œí•˜ì§€ ì•Šì•„ìš”. ğŸ˜¿"


